{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "24hackton_imageclassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqeFVTzX9Jnr",
        "colab_type": "text"
      },
      "source": [
        "##Import library & Load the dataset from gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiV_Pgy48-ZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e9d857b-6783-4608-8911-6734d40d328d"
      },
      "source": [
        "# Import all the necessary library & files!\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models  import Sequential, Model\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG0eGKYw9qMh",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl26RyCw9RH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = './gdrive/My Drive/24hackton/images'\n",
        "model_path = './gdrive/My Drive/24hackton/models'\n",
        "train_img_path = '{}/train'.format(image_path)\n",
        "val_img_path = '{}/val'.format(image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZq9tsin9ko8",
        "colab_type": "text"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHS-hCB_9UB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        rotation_range=25,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='reflect',\n",
        "        data_format='channels_last',\n",
        "        brightness_range=[0.5, 1.5],\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_img_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_img_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6tPqhRO90Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "Labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "print (Labels)\n",
        "print(train_generator[0][0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "075EjLiiN9Qc",
        "colab_type": "text"
      },
      "source": [
        "## Building of CNN Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1rv_Z07JBp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(dropout= True):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
        "                  activation='relu',\n",
        "                  input_shape=(224, 224, 3)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1000, activation='relu'))\n",
        "  model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# Save the best model with max val_acc using ModelCheckpoint\n",
        "checkpoint1 = ModelCheckpoint(\"{}/model.h5\".format(model_path), monitor='val_acc', verbose=3, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]\n",
        "\n",
        "# Define parameters\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}